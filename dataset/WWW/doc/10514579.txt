Detecting Wikipedia vandalism with active learning and statistical language models This paper proposes an active learning approach using language model statistics to detect Wikipedia vandalism . Wikipedia is a popular and influential collaborative information system . The collaborative nature of authoring , as well as the high visibility of its content , have exposed Wikipedia articles to vandalism . Vandalism is defined as malicious editing intended to compromise the integrity of the content of articles . Extensive manual efforts are being made to combat vandalism and an automated approach to alleviate the laborious process is needed . This paper builds statistical language models , constructing distributions of words from the revision history of Wikipedia articles . As vandalism often involves the use of unexpected words to draw attention , the fitness ( or lack thereof ) of a new edit when compared with language models built from previous versions may well indicate that an edit is a vandalism instance . In addition , the paper adopts an active learning model to solve the problem of noisy and incomplete labeling of Wikipedia vandalism . The Wikipedia domain with its revision histories offers a novel context in which to explore the potential of language models in characterizing author intention . As the experimental results presented in the paper demonstrate , these models hold promise for vandalism detection .
