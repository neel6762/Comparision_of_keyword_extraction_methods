{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incoming-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential modules for the algorithms\n",
    "from rake_nltk import Rake\n",
    "import yake\n",
    "from keybert import KeyBERT\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from numpy import array, log\n",
    "\n",
    "# data processing\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-third",
   "metadata": {},
   "source": [
    "### Importing the dataset\n",
    "- The dataset is pre-processed from the \"Pre-Processing-WWW.ipynb\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "played-massage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>distributed eigenvector computation,peer-to-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>automated reasoning,daml,distributed systems,o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>named graphs,semantic web,trust mechanisms,tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>ontology,semantic annotation of web services,s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>adaptive hypermedia,content adaptation,mobile ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_no                                           Abstract  \\\n",
       "0     183  eigentrust algorithm reputation management p p...   \n",
       "1   10119  simulation verification automated composition ...   \n",
       "2   11785  context content based trust policy semantic we...   \n",
       "3   12102  meteor web service annotation framework world ...   \n",
       "4   13109  detecting web page structure adaptive viewing ...   \n",
       "\n",
       "                                            Keywords  \n",
       "0  distributed eigenvector computation,peer-to-pe...  \n",
       "1  automated reasoning,daml,distributed systems,o...  \n",
       "2  named graphs,semantic web,trust mechanisms,tru...  \n",
       "3  ontology,semantic annotation of web services,s...  \n",
       "4  adaptive hypermedia,content adaptation,mobile ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('Data/Processed_WWW.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "durable-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data['Abstract'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecological-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_no = data['Doc_no'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-situation",
   "metadata": {},
   "source": [
    "### RAKE Algorithm\n",
    "- The following code block uses the rake_nltk module to extract ketwords from the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "italian-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in the text from the datafame and returns keywords\n",
    "def get_rake_keywords(docs):\n",
    "    r = Rake(min_length=2, max_length=3)\n",
    "    sr_no = 1\n",
    "    results = []\n",
    "    for row in docs:\n",
    "        #print(f'Processing : {sr_no}')\n",
    "        r.extract_keywords_from_text(row)\n",
    "        keywords = r.get_ranked_phrases()\n",
    "        keywords = keywords[:7]\n",
    "        keywords = \",\".join(keywords)\n",
    "        results.append(keywords)\n",
    "        sr_no += 1\n",
    "    rake_df = pd.DataFrame(zip(docs,results),columns=['Abstract','Extracted_Keywords'])\n",
    "    rake_df.insert(loc=0, column=\"Doc_no\", value=doc_no)\n",
    "    return rake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "advised-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Rake algorithm did not work well with pre-processed data, we applied the abstract from the \n",
    "rake_df = pd.read_pickle('Data/WWW.pkl')\n",
    "rake_docs = rake_df['Abstract'].tolist()\n",
    "rake_pred_df = get_rake_keywords(rake_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improving-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Extracted_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>The Eigentrust algorithm for reputation manage...</td>\n",
       "      <td>recent experience shows,global trust values,al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>Simulation , verification and automated compos...</td>\n",
       "      <td>order logical language,key application area,pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>Using context - and content-based trust polici...</td>\n",
       "      <td>specific data published,specific trust policie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>Meteor-s web service annotation framework The ...</td>\n",
       "      <td>first critical step,broadly adopted technology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>Detecting web page structure for adaptive view...</td>\n",
       "      <td>logically related units,experimental results s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>14449751</td>\n",
       "      <td>A flexible generative model for preference agg...</td>\n",
       "      <td>social choice face,preference aggregation prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>14453157</td>\n",
       "      <td>Evaluation with informational and navigational...</td>\n",
       "      <td>single `` entry,search result diversification,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>14453752</td>\n",
       "      <td>Template-based question answering over RDF dat...</td>\n",
       "      <td>natural language question,based question answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>14454508</td>\n",
       "      <td>ZenCrowd : leveraging probabilistic reasoning ...</td>\n",
       "      <td>make sensible decisions,dynamically generating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>14475693</td>\n",
       "      <td>Understanding task-driven information flow in ...</td>\n",
       "      <td>practice yet difficult,fixing software bugs,dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Doc_no                                           Abstract  \\\n",
       "0         183  The Eigentrust algorithm for reputation manage...   \n",
       "1       10119  Simulation , verification and automated compos...   \n",
       "2       11785  Using context - and content-based trust polici...   \n",
       "3       12102  Meteor-s web service annotation framework The ...   \n",
       "4       13109  Detecting web page structure for adaptive view...   \n",
       "..        ...                                                ...   \n",
       "495  14449751  A flexible generative model for preference agg...   \n",
       "496  14453157  Evaluation with informational and navigational...   \n",
       "497  14453752  Template-based question answering over RDF dat...   \n",
       "498  14454508  ZenCrowd : leveraging probabilistic reasoning ...   \n",
       "499  14475693  Understanding task-driven information flow in ...   \n",
       "\n",
       "                                    Extracted_Keywords  \n",
       "0    recent experience shows,global trust values,al...  \n",
       "1    order logical language,key application area,pr...  \n",
       "2    specific data published,specific trust policie...  \n",
       "3    first critical step,broadly adopted technology...  \n",
       "4    logically related units,experimental results s...  \n",
       "..                                                 ...  \n",
       "495  social choice face,preference aggregation prob...  \n",
       "496  single `` entry,search result diversification,...  \n",
       "497  natural language question,based question answe...  \n",
       "498  make sensible decisions,dynamically generating...  \n",
       "499  practice yet difficult,fixing software bugs,dr...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_pickle(rake_pred_df, 'www_results/rake_pred_df.pkl')\n",
    "rake_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-pixel",
   "metadata": {},
   "source": [
    "### YAKE Algorithm\n",
    "- The following code block uses the yake module to get keywords from the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "computational-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in the text from the datafame and returns keywords\n",
    "def get_yake_keywords(docs):\n",
    "    kw_extractor = yake.KeywordExtractor(n=2, top=7)\n",
    "    results = []\n",
    "    for row in docs:\n",
    "        keywords = kw_extractor.extract_keywords(row)\n",
    "        keys = []\n",
    "        for val in keywords:\n",
    "            keys.append(val[0])\n",
    "        results.append(\",\".join(keys))\n",
    "    yake_df = pd.DataFrame(zip(docs,results),columns=['Abstract','Extracted_Keywords'])\n",
    "    yake_df.insert(loc=0, column=\"Doc_no\", value=doc_no)\n",
    "    return yake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hawaiian-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "yake_pred_df = get_yake_keywords(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seven-circle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Extracted_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>global trust,inauthentic file,file sharing,dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>web service,service web,simulation verificatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>content based,context content,semantic web,bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>web service,semantic web,semantic annotation,s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>web page,mobile device,form factor,factor devi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>14449751</td>\n",
       "      <td>flexible generative model preference aggregati...</td>\n",
       "      <td>aggregation problem,existing method,preference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>14453157</td>\n",
       "      <td>evaluation informational navigational intent g...</td>\n",
       "      <td>intuitive metric,din ndcg,preference agreement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>14453752</td>\n",
       "      <td>template based question answering rdf data inc...</td>\n",
       "      <td>rdf data,question answering,answering rdf,incr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>14454508</td>\n",
       "      <td>zencrowd leveraging probabilistic reasoning cr...</td>\n",
       "      <td>improve quality,reasoning crowdsourcing,probab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>14475693</td>\n",
       "      <td>understanding task driven information flow col...</td>\n",
       "      <td>collaborative network,truncated power,power la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Doc_no                                           Abstract  \\\n",
       "0         183  eigentrust algorithm reputation management p p...   \n",
       "1       10119  simulation verification automated composition ...   \n",
       "2       11785  context content based trust policy semantic we...   \n",
       "3       12102  meteor web service annotation framework world ...   \n",
       "4       13109  detecting web page structure adaptive viewing ...   \n",
       "..        ...                                                ...   \n",
       "495  14449751  flexible generative model preference aggregati...   \n",
       "496  14453157  evaluation informational navigational intent g...   \n",
       "497  14453752  template based question answering rdf data inc...   \n",
       "498  14454508  zencrowd leveraging probabilistic reasoning cr...   \n",
       "499  14475693  understanding task driven information flow col...   \n",
       "\n",
       "                                    Extracted_Keywords  \n",
       "0    global trust,inauthentic file,file sharing,dec...  \n",
       "1    web service,service web,simulation verificatio...  \n",
       "2    content based,context content,semantic web,bas...  \n",
       "3    web service,semantic web,semantic annotation,s...  \n",
       "4    web page,mobile device,form factor,factor devi...  \n",
       "..                                                 ...  \n",
       "495  aggregation problem,existing method,preference...  \n",
       "496  intuitive metric,din ndcg,preference agreement...  \n",
       "497  rdf data,question answering,answering rdf,incr...  \n",
       "498  improve quality,reasoning crowdsourcing,probab...  \n",
       "499  collaborative network,truncated power,power la...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_pickle(yake_pred_df, 'www_results/yake_pred_df.pkl')\n",
    "yake_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-italian",
   "metadata": {},
   "source": [
    "## TF-IDF \n",
    "- The following code block uses the TF-IDF method from the Scikit-Learn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "moving-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_keywords(docs):\n",
    "    results = []\n",
    "    for row in docs:\n",
    "        vectorizer = CountVectorizer(ngram_range = (2,3))\n",
    "        X1 = vectorizer.fit_transform([row]) \n",
    "        features = (vectorizer.get_feature_names())\n",
    "        vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "        X2 = vectorizer.fit_transform([row])\n",
    "        scores = (X2.toarray())\n",
    "        sums = X2.sum(axis = 0)\n",
    "        data1 = []\n",
    "        for col, term in enumerate(features):\n",
    "            data1.append( (term, sums[0,col] ))\n",
    "        ranking = pd.DataFrame(data1, columns = ['term','rank'])\n",
    "        words = (ranking.sort_values('rank', ascending = False))\n",
    "        ex_keywords = []\n",
    "        for term in words['term'][:7]:\n",
    "            ex_keywords.append(term)\n",
    "        results.append(\",\".join(ex_keywords))\n",
    "    tf_idf_df = pd.DataFrame(zip(docs,results),columns=['Abstract','Extracted_Keywords'])\n",
    "    tf_idf_df.insert(loc=0, column=\"Doc_no\", value=doc_no)\n",
    "    return tf_idf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "common-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_pred_df = get_tf_idf_keywords(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "champion-johnston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Extracted_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>global trust value,global trust,trust value,in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>web service,web service web,simulation verific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>content based trust,based trust,semantic web,t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>web service,semantic web,data semantic,meteor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>web page,mobile device,form factor device,smal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>14449751</td>\n",
       "      <td>flexible generative model preference aggregati...</td>\n",
       "      <td>aggregation problem,preference aggregation,acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>14453157</td>\n",
       "      <td>evaluation informational navigational intent g...</td>\n",
       "      <td>din ndcg,intuitive metric,intent recall,metric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>14453752</td>\n",
       "      <td>template based question answering rdf data inc...</td>\n",
       "      <td>question answering,rdf data,accessing data,que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>14454508</td>\n",
       "      <td>zencrowd leveraging probabilistic reasoning cr...</td>\n",
       "      <td>reasoning crowdsourcing technique,reasoning cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>14475693</td>\n",
       "      <td>understanding task driven information flow col...</td>\n",
       "      <td>collaborative network,driven information,trunc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Doc_no                                           Abstract  \\\n",
       "0         183  eigentrust algorithm reputation management p p...   \n",
       "1       10119  simulation verification automated composition ...   \n",
       "2       11785  context content based trust policy semantic we...   \n",
       "3       12102  meteor web service annotation framework world ...   \n",
       "4       13109  detecting web page structure adaptive viewing ...   \n",
       "..        ...                                                ...   \n",
       "495  14449751  flexible generative model preference aggregati...   \n",
       "496  14453157  evaluation informational navigational intent g...   \n",
       "497  14453752  template based question answering rdf data inc...   \n",
       "498  14454508  zencrowd leveraging probabilistic reasoning cr...   \n",
       "499  14475693  understanding task driven information flow col...   \n",
       "\n",
       "                                    Extracted_Keywords  \n",
       "0    global trust value,global trust,trust value,in...  \n",
       "1    web service,web service web,simulation verific...  \n",
       "2    content based trust,based trust,semantic web,t...  \n",
       "3    web service,semantic web,data semantic,meteor ...  \n",
       "4    web page,mobile device,form factor device,smal...  \n",
       "..                                                 ...  \n",
       "495  aggregation problem,preference aggregation,acc...  \n",
       "496  din ndcg,intuitive metric,intent recall,metric...  \n",
       "497  question answering,rdf data,accessing data,que...  \n",
       "498  reasoning crowdsourcing technique,reasoning cr...  \n",
       "499  collaborative network,driven information,trunc...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_pickle(tf_idf_pred_df, 'www_results/tf_idf_pred_df.pkl')\n",
    "tf_idf_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-armstrong",
   "metadata": {},
   "source": [
    "### KeyBert Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "saved-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keybert_keywords(docs):\n",
    "    model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "    results = []\n",
    "    doc_no = 1\n",
    "    for row in docs:\n",
    "        keywords = model.extract_keywords(row, keyphrase_ngram_range=(2, 3), stop_words=None)\n",
    "        temp_keys = []\n",
    "        for val in keywords:\n",
    "            temp_keys.append(val[0])\n",
    "        results.append(\",\".join(temp_keys))\n",
    "        doc_no += 1\n",
    "    key_bert_df = pd.DataFrame(zip(docs,results),columns=['Abstract','Extracted_Keywords'])\n",
    "    key_bert_df.insert(loc=0, column=\"Doc_no\", value=doc_no)\n",
    "    return key_bert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "armed-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_bert_pred_df = get_keybert_keywords(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sticky-airfare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Extracted_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>malicious peer isolates,file algorithm decreas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>evolution semantic web,semantic web proliferat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>501</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>semantic web trust,policy semantic web,web tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>501</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>better framework web,web create better,better ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>501</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>page designed desktop,detecting web page,desig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>501</td>\n",
       "      <td>flexible generative model preference aggregati...</td>\n",
       "      <td>aggregation problem multiple,aggregation probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>501</td>\n",
       "      <td>evaluation informational navigational intent g...</td>\n",
       "      <td>search result diversification,diversity metric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>501</td>\n",
       "      <td>template based question answering rdf data inc...</td>\n",
       "      <td>result expressive query,question triple matche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>501</td>\n",
       "      <td>zencrowd leveraging probabilistic reasoning cr...</td>\n",
       "      <td>probabilistic reasoning crowdsourcing,task onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>501</td>\n",
       "      <td>understanding task driven information flow col...</td>\n",
       "      <td>network model study,driven information routing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Doc_no                                           Abstract  \\\n",
       "0       501  eigentrust algorithm reputation management p p...   \n",
       "1       501  simulation verification automated composition ...   \n",
       "2       501  context content based trust policy semantic we...   \n",
       "3       501  meteor web service annotation framework world ...   \n",
       "4       501  detecting web page structure adaptive viewing ...   \n",
       "..      ...                                                ...   \n",
       "495     501  flexible generative model preference aggregati...   \n",
       "496     501  evaluation informational navigational intent g...   \n",
       "497     501  template based question answering rdf data inc...   \n",
       "498     501  zencrowd leveraging probabilistic reasoning cr...   \n",
       "499     501  understanding task driven information flow col...   \n",
       "\n",
       "                                    Extracted_Keywords  \n",
       "0    malicious peer isolates,file algorithm decreas...  \n",
       "1    evolution semantic web,semantic web proliferat...  \n",
       "2    semantic web trust,policy semantic web,web tru...  \n",
       "3    better framework web,web create better,better ...  \n",
       "4    page designed desktop,detecting web page,desig...  \n",
       "..                                                 ...  \n",
       "495  aggregation problem multiple,aggregation probl...  \n",
       "496  search result diversification,diversity metric...  \n",
       "497  result expressive query,question triple matche...  \n",
       "498  probabilistic reasoning crowdsourcing,task onl...  \n",
       "499  network model study,driven information routing...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_pickle(key_bert_pred_df, 'www_results/key_bert_pred_df.pkl')\n",
    "key_bert_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-mortality",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "solid-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "heated-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_keywords(docs):\n",
    "    results = []\n",
    "    for row in docs:\n",
    "        vectorizer = CountVectorizer(ngram_range=(3,3))\n",
    "        tf = vectorizer.fit_transform([row])\n",
    "        tf_feature_names = vectorizer.get_feature_names()\n",
    "        number_of_topics = 1\n",
    "        model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)\n",
    "        model.fit(tf)\n",
    "        no_top_words = 7\n",
    "        result_dict = display_topics(model, tf_feature_names, no_top_words)\n",
    "        kw = result_dict['Topic 0 words']\n",
    "        results.append(\",\".join(kw))\n",
    "    lda = pd.DataFrame(zip(docs,results),columns=['Abstract','Extracted_Keywords'])\n",
    "    lda.insert(loc=0, column=\"Doc_no\", value=doc_no)\n",
    "    return lda  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "powerful-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pred_df = get_lda_keywords(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "becoming-coating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Extracted_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>global trust value,peer peer file,peer file sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>web service web,composition web service,implem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>content based trust,context content based,base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>service annotation framework,web service annot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>device web page,small form factor,form factor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>14449751</td>\n",
       "      <td>flexible generative model preference aggregati...</td>\n",
       "      <td>work formulate flexible,variety form make,gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>14453157</td>\n",
       "      <td>evaluation informational navigational intent g...</td>\n",
       "      <td>metric intuitive metric,intuitive metric empha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>14453752</td>\n",
       "      <td>template based question answering rdf data inc...</td>\n",
       "      <td>way accessing data,identification predicate de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>14454508</td>\n",
       "      <td>zencrowd leveraging probabilistic reasoning cr...</td>\n",
       "      <td>reasoning crowdsourcing technique,probabilisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>14475693</td>\n",
       "      <td>understanding task driven information flow col...</td>\n",
       "      <td>truncated power law,task driven information,ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Doc_no                                           Abstract  \\\n",
       "0         183  eigentrust algorithm reputation management p p...   \n",
       "1       10119  simulation verification automated composition ...   \n",
       "2       11785  context content based trust policy semantic we...   \n",
       "3       12102  meteor web service annotation framework world ...   \n",
       "4       13109  detecting web page structure adaptive viewing ...   \n",
       "..        ...                                                ...   \n",
       "495  14449751  flexible generative model preference aggregati...   \n",
       "496  14453157  evaluation informational navigational intent g...   \n",
       "497  14453752  template based question answering rdf data inc...   \n",
       "498  14454508  zencrowd leveraging probabilistic reasoning cr...   \n",
       "499  14475693  understanding task driven information flow col...   \n",
       "\n",
       "                                    Extracted_Keywords  \n",
       "0    global trust value,peer peer file,peer file sh...  \n",
       "1    web service web,composition web service,implem...  \n",
       "2    content based trust,context content based,base...  \n",
       "3    service annotation framework,web service annot...  \n",
       "4    device web page,small form factor,form factor ...  \n",
       "..                                                 ...  \n",
       "495  work formulate flexible,variety form make,gene...  \n",
       "496  metric intuitive metric,intuitive metric empha...  \n",
       "497  way accessing data,identification predicate de...  \n",
       "498  reasoning crowdsourcing technique,probabilisti...  \n",
       "499  truncated power law,task driven information,ne...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_pickle(lda_pred_df, 'www_results/lda_pred_df.pkl')\n",
    "lda_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-might",
   "metadata": {},
   "source": [
    "### PositionRank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "central-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positionrank_keywords(docs):\n",
    "    results = []\n",
    "    for row in docs:\n",
    "        # load a spaCy model\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "        # add PyTextRank to the spaCy pipeline\n",
    "        nlp.add_pipe(\"positionrank\") #positionrank\n",
    "        doc = nlp(row)\n",
    "\n",
    "        # examine the top-ranked phrases in the document\n",
    "        limit = len(doc._.phrases)\n",
    "        kw = []\n",
    "        if(limit > 4):\n",
    "            for phrase in doc._.phrases:\n",
    "                if(len(phrase.text.split()) <= 4 and len(phrase.text.split()) > 1):\n",
    "                    kw.append(phrase.text)\n",
    "            kw = \",\".join(kw)\n",
    "            results.append(kw)\n",
    "        else:\n",
    "            for phrase in doc._.phrases:\n",
    "                kw.append(phrase.text)\n",
    "            kw = \",\".join(kw)\n",
    "            results.append(kw)\n",
    "    pos_rank_df = pd.DataFrame(zip(docs,results),columns=['Abstract','Extracted_Keywords'])\n",
    "    pos_rank_df.insert(loc=0, column=\"Doc_no\", value=doc_no)\n",
    "    return pos_rank_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rank_pred_df = get_positionrank_keywords(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(pos_rank_pred_df, 'www_results/pos_rank_pred_df.pkl')\n",
    "pos_rank_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-consciousness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
