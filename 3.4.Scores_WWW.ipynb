{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vocational-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Evaluation Metrics (ROUGE)\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-focus",
   "metadata": {},
   "source": [
    "### Reading all the predicted_files for evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hairy-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAKE predictions\n",
    "rake_pred_df = pd.read_pickle('www_results/rake_pred_df.pkl')\n",
    "\n",
    "# YAKE predictions\n",
    "yake_pred_df = pd.read_pickle('www_results/yake_pred_df.pkl')\n",
    "\n",
    "# TF-IDF predictions\n",
    "tf_idf_pred_df = pd.read_pickle('www_results/tf_idf_pred_df.pkl')\n",
    "\n",
    "# KeyBERT predictions\n",
    "key_bert_pred_df = pd.read_pickle('www_results/key_bert_pred_df.pkl')\n",
    "\n",
    "# LDA predictions\n",
    "lda_pred_df = pd.read_pickle('www_results/lda_pred_df.pkl')\n",
    "\n",
    "# PositionRank predictions\n",
    "pr_pred_df = pd.read_pickle('www_results/pos_rank_pred_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-black",
   "metadata": {},
   "source": [
    "### Refrence Dataset with labeled keywords\n",
    "- This data frame is used to evalute the results for the predicted keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "institutional-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/Processed_WWW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "russian-florence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>distributed eigenvector computation,peer-to-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>automated reasoning,daml,distributed systems,o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>named graphs,semantic web,trust mechanisms,tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>ontology,semantic annotation of web services,s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>adaptive hypermedia,content adaptation,mobile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>14449751</td>\n",
       "      <td>flexible generative model preference aggregati...</td>\n",
       "      <td>collaborative filtering,learning,meta search,p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>14453157</td>\n",
       "      <td>evaluation informational navigational intent g...</td>\n",
       "      <td>diversification,evaluation,information search ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>14453752</td>\n",
       "      <td>template based question answering rdf data inc...</td>\n",
       "      <td>natural language patterns,question answering,s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>14454508</td>\n",
       "      <td>zencrowd leveraging probabilistic reasoning cr...</td>\n",
       "      <td>crowdsourcing,entity linking,linked data,proba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>14475693</td>\n",
       "      <td>understanding task driven information flow col...</td>\n",
       "      <td>collaborative network,information flow,social ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Doc_no                                           Abstract  \\\n",
       "0         183  eigentrust algorithm reputation management p p...   \n",
       "1       10119  simulation verification automated composition ...   \n",
       "2       11785  context content based trust policy semantic we...   \n",
       "3       12102  meteor web service annotation framework world ...   \n",
       "4       13109  detecting web page structure adaptive viewing ...   \n",
       "..        ...                                                ...   \n",
       "495  14449751  flexible generative model preference aggregati...   \n",
       "496  14453157  evaluation informational navigational intent g...   \n",
       "497  14453752  template based question answering rdf data inc...   \n",
       "498  14454508  zencrowd leveraging probabilistic reasoning cr...   \n",
       "499  14475693  understanding task driven information flow col...   \n",
       "\n",
       "                                              Keywords  \n",
       "0    distributed eigenvector computation,peer-to-pe...  \n",
       "1    automated reasoning,daml,distributed systems,o...  \n",
       "2    named graphs,semantic web,trust mechanisms,tru...  \n",
       "3    ontology,semantic annotation of web services,s...  \n",
       "4    adaptive hypermedia,content adaptation,mobile ...  \n",
       "..                                                 ...  \n",
       "495  collaborative filtering,learning,meta search,p...  \n",
       "496  diversification,evaluation,information search ...  \n",
       "497  natural language patterns,question answering,s...  \n",
       "498  crowdsourcing,entity linking,linked data,proba...  \n",
       "499  collaborative network,information flow,social ...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indonesian-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_no = data['Doc_no']\n",
    "abstracts = data['Abstract']\n",
    "refrence_data = data['Keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "japanese-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All the algorithms realted results\n",
    "\"\"\"\n",
    "algorithm = [\"RAKE\", \"YAKE\", \"TF-IDF\", \"KeyBERT\", \"LDA\", \"Position Rank\"]\n",
    "algo_precision_scores = []\n",
    "algo_recall_scores = []\n",
    "algo_f1_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-hanging",
   "metadata": {},
   "source": [
    "### ROUGE Metrics for Evaluation of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acknowledged-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function returns the average of precision, recall and f1score\n",
    "based on the score from rouge1, rouge2, rougeL rounding off the final \n",
    "value to 2 decimal places for each doc in the dataset\n",
    "\"\"\"\n",
    "def get_avg_scores(result):\n",
    "    precision_score = []\n",
    "    recall_score = []\n",
    "    f1_score = []\n",
    "    for rouge in ['rouge1','rouge2','rougeL']:\n",
    "        precision_score.append(result[rouge][0]*2)\n",
    "        recall_score.append(result[rouge][1]*2)\n",
    "        f1_score.append(result[rouge][2]*2)\n",
    "    precision_score = np.round(np.average(precision_score), 2)\n",
    "    recall_score = np.round(np.average(recall_score), 2)\n",
    "    f1_score = np.round(np.average(f1_score), 2)\n",
    "    return precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "honest-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Rouge_scores(refrence_data, test_data):\n",
    "    precision_score = []\n",
    "    recall_score = []\n",
    "    f1_score = []\n",
    "    \n",
    "    for refrence, test in zip(refrence_data, test_data):\n",
    "        \n",
    "        # modifying the format as a string with spaces\n",
    "        refrence = refrence.replace(\",\", \" \")\n",
    "        test = test.replace(\",\", \" \")\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(refrence, test)\n",
    "        \n",
    "        # Getting the avg scores and appending them to the list\n",
    "        p_score, r_score, f_score = get_avg_scores(scores)\n",
    "        precision_score.append(p_score)\n",
    "        recall_score.append(r_score)\n",
    "        f1_score.append(f_score)\n",
    "        \n",
    "    results_df = pd.DataFrame(zip(doc_no,abstracts,precision_score, recall_score, f1_score), columns=['Doc_no', 'Abstract','Avg_precision_score','Avg_recall_score','Avg_f1_score'])\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "national-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This method returns the average scores for \n",
    "Precison, Recall and F1 \n",
    "on the whole document\n",
    "\"\"\"\n",
    "def get_final_results(result):\n",
    "    return np.average(result['Avg_precision_score']),np.average(result['Avg_recall_score']),np.average(result['Avg_f1_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-navigator",
   "metadata": {},
   "source": [
    "### Results for the RAKE Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "structured-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_data = rake_pred_df['Extracted_Keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "scientific-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_results = get_Rouge_scores(refrence_data, rake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "imposed-replacement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Avg_precision_score</th>\n",
       "      <th>Avg_recall_score</th>\n",
       "      <th>Avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_no                                           Abstract  \\\n",
       "0     183  eigentrust algorithm reputation management p p...   \n",
       "1   10119  simulation verification automated composition ...   \n",
       "2   11785  context content based trust policy semantic we...   \n",
       "3   12102  meteor web service annotation framework world ...   \n",
       "4   13109  detecting web page structure adaptive viewing ...   \n",
       "\n",
       "   Avg_precision_score  Avg_recall_score  Avg_f1_score  \n",
       "0                 0.13              0.38          0.20  \n",
       "1                 0.58              0.87          0.69  \n",
       "2                 0.29              0.77          0.42  \n",
       "3                 0.51              0.83          0.63  \n",
       "4                 0.06              0.22          0.10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rake_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vocal-individual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- RAKE RESULTS ----------------\n",
      "1. Avg. Precision score on the whole document : 0.20918\n",
      "2. Avg. Recall score on the whole document : 0.48929999999999996\n",
      "3. Avg. F1 score on the whole document : 0.28082\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- RAKE RESULTS ----------------\")\n",
    "final_res = get_final_results(rake_results)\n",
    "algo_precision_scores.append(final_res[0])\n",
    "algo_recall_scores.append(final_res[1])\n",
    "algo_f1_scores.append(final_res[2])\n",
    "print(f\"1. Avg. Precision score on the whole document : {final_res[0]}\")\n",
    "print(f\"2. Avg. Recall score on the whole document : {final_res[1]}\")\n",
    "print(f\"3. Avg. F1 score on the whole document : {final_res[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-source",
   "metadata": {},
   "source": [
    "### Results for the YAKE Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rocky-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "yake_data = yake_pred_df['Extracted_Keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "permanent-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "yake_results = get_Rouge_scores(refrence_data, yake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ultimate-harassment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Avg_precision_score</th>\n",
       "      <th>Avg_recall_score</th>\n",
       "      <th>Avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_no                                           Abstract  \\\n",
       "0     183  eigentrust algorithm reputation management p p...   \n",
       "1   10119  simulation verification automated composition ...   \n",
       "2   11785  context content based trust policy semantic we...   \n",
       "3   12102  meteor web service annotation framework world ...   \n",
       "4   13109  detecting web page structure adaptive viewing ...   \n",
       "\n",
       "   Avg_precision_score  Avg_recall_score  Avg_f1_score  \n",
       "0                 0.19              0.38          0.25  \n",
       "1                 0.79              0.73          0.76  \n",
       "2                 0.78              1.38          0.99  \n",
       "3                 0.87              0.94          0.90  \n",
       "4                 0.10              0.22          0.13  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yake_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "identified-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- YAKE RESULTS ----------------\n",
      "1. Avg. Precision score on the whole document : 0.31689999999999996\n",
      "2. Avg. Recall score on the whole document : 0.5381400000000001\n",
      "3. Avg. F1 score on the whole document : 0.38094\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- YAKE RESULTS ----------------\")\n",
    "final_res = get_final_results(yake_results)\n",
    "algo_precision_scores.append(final_res[0])\n",
    "algo_recall_scores.append(final_res[1])\n",
    "algo_f1_scores.append(final_res[2])\n",
    "print(f\"1. Avg. Precision score on the whole document : {final_res[0]}\")\n",
    "print(f\"2. Avg. Recall score on the whole document : {final_res[1]}\")\n",
    "print(f\"3. Avg. F1 score on the whole document : {final_res[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-namibia",
   "metadata": {},
   "source": [
    "### Results for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "secret-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_data = tf_idf_pred_df['Extracted_Keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "champion-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_results = get_Rouge_scores(refrence_data, tf_idf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "twelve-volume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Avg_precision_score</th>\n",
       "      <th>Avg_recall_score</th>\n",
       "      <th>Avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_no                                           Abstract  \\\n",
       "0     183  eigentrust algorithm reputation management p p...   \n",
       "1   10119  simulation verification automated composition ...   \n",
       "2   11785  context content based trust policy semantic we...   \n",
       "3   12102  meteor web service annotation framework world ...   \n",
       "4   13109  detecting web page structure adaptive viewing ...   \n",
       "\n",
       "   Avg_precision_score  Avg_recall_score  Avg_f1_score  \n",
       "0                 0.17              0.38          0.23  \n",
       "1                 0.76              0.88          0.82  \n",
       "2                 0.51              1.04          0.68  \n",
       "3                 0.84              1.10          0.95  \n",
       "4                 0.08              0.22          0.12  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "several-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- TF-IDF RESULTS ----------------\n",
      "1. Avg. Precision score on the whole document : 0.29954000000000003\n",
      "2. Avg. Recall score on the whole document : 0.5691600000000001\n",
      "3. Avg. F1 score on the whole document : 0.37492000000000003\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- TF-IDF RESULTS ----------------\")\n",
    "final_res = get_final_results(tf_idf_results)\n",
    "algo_precision_scores.append(final_res[0])\n",
    "algo_recall_scores.append(final_res[1])\n",
    "algo_f1_scores.append(final_res[2])\n",
    "print(f\"1. Avg. Precision score on the whole document : {final_res[0]}\")\n",
    "print(f\"2. Avg. Recall score on the whole document : {final_res[1]}\")\n",
    "print(f\"3. Avg. F1 score on the whole document : {final_res[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-positive",
   "metadata": {},
   "source": [
    "### Results for KeyBert Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "legal-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_data = key_bert_pred_df['Extracted_Keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "informed-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_results = get_Rouge_scores(refrence_data, kb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sound-recording",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Avg_precision_score</th>\n",
       "      <th>Avg_recall_score</th>\n",
       "      <th>Avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_no                                           Abstract  \\\n",
       "0     183  eigentrust algorithm reputation management p p...   \n",
       "1   10119  simulation verification automated composition ...   \n",
       "2   11785  context content based trust policy semantic we...   \n",
       "3   12102  meteor web service annotation framework world ...   \n",
       "4   13109  detecting web page structure adaptive viewing ...   \n",
       "\n",
       "   Avg_precision_score  Avg_recall_score  Avg_f1_score  \n",
       "0                 0.09              0.19          0.12  \n",
       "1                 0.54              0.58          0.56  \n",
       "2                 0.59              1.12          0.77  \n",
       "3                 0.27              0.31          0.29  \n",
       "4                 0.00              0.00          0.00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "respective-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- KeyBERT RESULTS ----------------\n",
      "1. Avg. Precision score on the whole document : 0.25610000000000005\n",
      "2. Avg. Recall score on the whole document : 0.45124000000000003\n",
      "3. Avg. F1 score on the whole document : 0.31272000000000005\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- KeyBERT RESULTS ----------------\")\n",
    "final_res = get_final_results(kb_results)\n",
    "algo_precision_scores.append(final_res[0])\n",
    "algo_recall_scores.append(final_res[1])\n",
    "algo_f1_scores.append(final_res[2])\n",
    "print(f\"1. Avg. Precision score on the whole document : {final_res[0]}\")\n",
    "print(f\"2. Avg. Recall score on the whole document : {final_res[1]}\")\n",
    "print(f\"3. Avg. F1 score on the whole document : {final_res[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-girlfriend",
   "metadata": {},
   "source": [
    "### Results for LDA Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "returning-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_data = lda_pred_df['Extracted_Keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adapted-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_results = get_Rouge_scores(refrence_data, lda_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "green-display",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Avg_precision_score</th>\n",
       "      <th>Avg_recall_score</th>\n",
       "      <th>Avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_no                                           Abstract  \\\n",
       "0     183  eigentrust algorithm reputation management p p...   \n",
       "1   10119  simulation verification automated composition ...   \n",
       "2   11785  context content based trust policy semantic we...   \n",
       "3   12102  meteor web service annotation framework world ...   \n",
       "4   13109  detecting web page structure adaptive viewing ...   \n",
       "\n",
       "   Avg_precision_score  Avg_recall_score  Avg_f1_score  \n",
       "0                 0.13              0.38          0.19  \n",
       "1                 0.51              0.77          0.62  \n",
       "2                 0.39              1.04          0.56  \n",
       "3                 0.54              0.88          0.67  \n",
       "4                 0.00              0.00          0.00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "union-census",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- LDA RESULTS ----------------\n",
      "1. Avg. Precision score on the whole document : 0.20872\n",
      "2. Avg. Recall score on the whole document : 0.52298\n",
      "3. Avg. F1 score on the whole document : 0.28778\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- LDA RESULTS ----------------\")\n",
    "final_res = get_final_results(lda_results)\n",
    "algo_precision_scores.append(final_res[0])\n",
    "algo_recall_scores.append(final_res[1])\n",
    "algo_f1_scores.append(final_res[2])\n",
    "print(f\"1. Avg. Precision score on the whole document : {final_res[0]}\")\n",
    "print(f\"2. Avg. Recall score on the whole document : {final_res[1]}\")\n",
    "print(f\"3. Avg. F1 score on the whole document : {final_res[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-truck",
   "metadata": {},
   "source": [
    "### Results for PositionRank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "casual-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_data = pr_pred_df['Extracted_Keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "annual-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_results = get_Rouge_scores(refrence_data, pr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "changed-friend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_no</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Avg_precision_score</th>\n",
       "      <th>Avg_recall_score</th>\n",
       "      <th>Avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>eigentrust algorithm reputation management p p...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10119</td>\n",
       "      <td>simulation verification automated composition ...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11785</td>\n",
       "      <td>context content based trust policy semantic we...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102</td>\n",
       "      <td>meteor web service annotation framework world ...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109</td>\n",
       "      <td>detecting web page structure adaptive viewing ...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_no                                           Abstract  \\\n",
       "0     183  eigentrust algorithm reputation management p p...   \n",
       "1   10119  simulation verification automated composition ...   \n",
       "2   11785  context content based trust policy semantic we...   \n",
       "3   12102  meteor web service annotation framework world ...   \n",
       "4   13109  detecting web page structure adaptive viewing ...   \n",
       "\n",
       "   Avg_precision_score  Avg_recall_score  Avg_f1_score  \n",
       "0                 0.14              0.57          0.23  \n",
       "1                 0.45              0.68          0.54  \n",
       "2                 0.99              1.12          1.05  \n",
       "3                 0.60              0.78          0.68  \n",
       "4                 0.05              0.22          0.08  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "endangered-genesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- PositionRank RESULTS ----------------\n",
      "1. Avg. Precision score on the whole document : 0.2101\n",
      "2. Avg. Recall score on the whole document : 0.46776\n",
      "3. Avg. F1 score on the whole document : 0.26124\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- PositionRank RESULTS ----------------\")\n",
    "final_res = get_final_results(pr_results)\n",
    "algo_precision_scores.append(final_res[0])\n",
    "algo_recall_scores.append(final_res[1])\n",
    "algo_f1_scores.append(final_res[2])\n",
    "print(f\"1. Avg. Precision score on the whole document : {final_res[0]}\")\n",
    "print(f\"2. Avg. Recall score on the whole document : {final_res[1]}\")\n",
    "print(f\"3. Avg. F1 score on the whole document : {final_res[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-conspiracy",
   "metadata": {},
   "source": [
    "### Comparing the overall results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "interior-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_comparision = pd.DataFrame(zip(algorithm, algo_precision_scores, algo_recall_scores, algo_f1_scores), columns=['Algorithm','Avg Precision Score', 'Avg Recall Score','Avg F1 Scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "protective-kitty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Comparision of various algorithms for keywords extraction on WWW dataset -----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Avg Precision Score</th>\n",
       "      <th>Avg Recall Score</th>\n",
       "      <th>Avg F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAKE</td>\n",
       "      <td>0.20918</td>\n",
       "      <td>0.48930</td>\n",
       "      <td>0.28082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YAKE</td>\n",
       "      <td>0.31690</td>\n",
       "      <td>0.53814</td>\n",
       "      <td>0.38094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.29954</td>\n",
       "      <td>0.56916</td>\n",
       "      <td>0.37492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KeyBERT</td>\n",
       "      <td>0.25610</td>\n",
       "      <td>0.45124</td>\n",
       "      <td>0.31272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.20872</td>\n",
       "      <td>0.52298</td>\n",
       "      <td>0.28778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Position Rank</td>\n",
       "      <td>0.21010</td>\n",
       "      <td>0.46776</td>\n",
       "      <td>0.26124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algorithm  Avg Precision Score  Avg Recall Score  Avg F1 Scores\n",
       "0           RAKE              0.20918           0.48930        0.28082\n",
       "1           YAKE              0.31690           0.53814        0.38094\n",
       "2         TF-IDF              0.29954           0.56916        0.37492\n",
       "3        KeyBERT              0.25610           0.45124        0.31272\n",
       "4            LDA              0.20872           0.52298        0.28778\n",
       "5  Position Rank              0.21010           0.46776        0.26124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n----- Comparision of various algorithms for keywords extraction on WWW dataset -----\")\n",
    "display(algo_comparision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-narrow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
